{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow tutorial\n",
    "https://www.tensorflow.org/get_started/get_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# константы\n",
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0)   # implicitly float32\n",
    "print node1, node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# запуск графа на исполнение требует создания сессии\n",
    "sess = tf.Session()\n",
    "print sess.run([node1, node2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_2:0\", shape=(), dtype=float32)\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "# операции над тензорами тоже являются нодами\n",
    "node3 = tf.add(node1, node2)\n",
    "print node3\n",
    "print sess.run(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "[ 4.  7.]\n"
     ]
    }
   ],
   "source": [
    "# входные данные задаются с помощью узлов типа placeholder\n",
    "a = tf.placeholder(dtype=tf.float32)\n",
    "b = tf.placeholder(dtype=tf.float32)\n",
    "adder_node = a + b\n",
    "\n",
    "print sess.run(adder_node, {a: 3, b: 5})\n",
    "print sess.run(adder_node, {a: [1, 2], b: [3, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30000001  0.          0.30000001]\n"
     ]
    }
   ],
   "source": [
    "# ноды типа Variable, значения которых могут меняться (мутабельные)\n",
    "w = tf.Variable(initial_value=[0.3], dtype=tf.float32)\n",
    "b = tf.Variable(initial_value=[-0.3], dtype=tf.float32)\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "linear_model = w * x + b\n",
    "\n",
    "# в отличие от констант, переменные в тензорфлоу требуют явной инициализации\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# граф можно выполнить для нескольких входных значений плейсхолдера\n",
    "print sess.run(linear_model, {x: [0.0, 1.0, 2.0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "# целевая функция для линейной модели: квадратичная ошибка\n",
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "\n",
    "print sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# вручную изменить значение переменной ноды можно с помощью операции assign \n",
    "fix_w = tf.assign(w, [-1.0])\n",
    "fix_b = tf.assign(b, [1.0])\n",
    "sess.run([fix_w, fix_b])\n",
    "\n",
    "print sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32), 5.6999738e-11]\n"
     ]
    }
   ],
   "source": [
    "# использование автоматических градиентов и оптимизатора\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# реинициализируем переменные\n",
    "sess.run(init)\n",
    "\n",
    "# обучаем \n",
    "for i in xrange(1000):\n",
    "    sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    \n",
    "# выводим результат\n",
    "print sess.run([w, b, loss], {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpB26VWL\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x119c36590>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpB26VWL', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpB26VWL/model.ckpt.\n",
      "INFO:tensorflow:loss = 18.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 966.314\n",
      "INFO:tensorflow:loss = 0.122829, step = 101 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1136.27\n",
      "INFO:tensorflow:loss = 0.0414071, step = 201 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1029.57\n",
      "INFO:tensorflow:loss = 0.0237315, step = 301 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1122.61\n",
      "INFO:tensorflow:loss = 0.00400706, step = 401 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 883.689\n",
      "INFO:tensorflow:loss = 0.00251567, step = 501 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 811.149\n",
      "INFO:tensorflow:loss = 0.000503647, step = 601 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.617\n",
      "INFO:tensorflow:loss = 3.71325e-05, step = 701 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.486\n",
      "INFO:tensorflow:loss = 4.29549e-05, step = 801 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 1047.68\n",
      "INFO:tensorflow:loss = 9.32346e-06, step = 901 (0.096 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpB26VWL/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.73038e-07.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-02-11:24:59\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpB26VWL/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-02-11:25:00\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 5.24275e-07, global_step = 1000, loss = 2.0971e-06\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-02-11:25:00\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpB26VWL/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-02-11:25:00\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00257852, global_step = 1000, loss = 0.0103141\n",
      "train metrics: {'average_loss': 5.2427475e-07, 'global_step': 1000, 'loss': 2.097099e-06}\n",
      "eval metrics: {'average_loss': 0.0025785188, 'global_step': 1000, 'loss': 0.010314075}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument <tensorflow.python.estimator.canned.linear.LinearRegressor object at 0x119c83390> has invalid type <class 'tensorflow.python.estimator.canned.linear.LinearRegressor'>, must be a string or Tensor. (Can not convert a LinearRegressor into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-979c44e751d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"eval metrics: %r\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0meval_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/stys/anaconda/envs/edward/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stys/anaconda/envs/edward/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1105\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stys/anaconda/envs/edward/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \"\"\"\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stys/anaconda/envs/edward/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/Users/stys/anaconda/envs/edward/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    273\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    274\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    276\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument <tensorflow.python.estimator.canned.linear.LinearRegressor object at 0x119c83390> has invalid type <class 'tensorflow.python.estimator.canned.linear.LinearRegressor'>, must be a string or Tensor. (Can not convert a LinearRegressor into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "# более высокоуровневое API: tf.estimator\n",
    "\n",
    "# создаем список фичей (в случае одномерной линейной регресии используем одну фичу)\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# создаем экземпляр модели\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# использование numpy\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print \"train metrics: %r\"% train_metrics\n",
    "print \"eval metrics: %r\"% eval_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpJzVthX\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11ac9a710>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpJzVthX', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpJzVthX/model.ckpt.\n",
      "INFO:tensorflow:loss = 53.6989671039, step = 1\n",
      "INFO:tensorflow:global_step/sec: 995.312\n",
      "INFO:tensorflow:loss = 0.661202087612, step = 101 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1153.19\n",
      "INFO:tensorflow:loss = 0.0633381699483, step = 201 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1158.96\n",
      "INFO:tensorflow:loss = 0.00416307579033, step = 301 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1151.81\n",
      "INFO:tensorflow:loss = 0.000307743531176, step = 401 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1104.9\n",
      "INFO:tensorflow:loss = 1.12507062197e-05, step = 501 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1005.61\n",
      "INFO:tensorflow:loss = 2.73352690532e-06, step = 601 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1031.29\n",
      "INFO:tensorflow:loss = 4.22231469292e-07, step = 701 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1076\n",
      "INFO:tensorflow:loss = 2.54703700275e-08, step = 801 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1013.14\n",
      "INFO:tensorflow:loss = 1.55507445557e-09, step = 901 (0.097 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpJzVthX/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.64685435844e-10.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-02-11:37:02\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpJzVthX/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-02-11:37:03\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.91022e-10\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-02-11:37:03\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/c3/tly0db3j0j1_t1vgkhvtw0jnhg_gr1/T/tmpJzVthX/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-02-11:37:03\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101013\n",
      "train metrics: {'loss': 1.9102234e-10, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010101301, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    # Build a linear model and predict values\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    y = W*features['x'] + b\n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    # Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "    # EstimatorSpec connects subgraphs we built to the\n",
    "    # appropriate functionality.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7., 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:edward]",
   "language": "python",
   "name": "conda-env-edward-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
